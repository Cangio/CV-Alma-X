{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marker recognition performances\n",
    "Marker recognition should be done in real time during rover exploration.\\\n",
    "Depending on the platform used to run the code, significant different time execution has been obtained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries once\n",
    "import numpy as np\n",
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Constant parameters used in Aruco methods\n",
    "ARUCO_PARAMETERS = aruco.DetectorParameters_create()\n",
    "ARUCO_DICT = aruco.Dictionary_get(aruco.DICT_5X5_50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original, colored image\n",
    "First we evaluate the plain function performance, given a non-filtered colored jpg image at **full resolution**. Photos are taken from smartphone with native resolution of 1960x4032:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolution: 1960x4032\n",
      "227 ms ± 23.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Read the image with the markers\n",
    "queryImg = cv2.imread(\"test-imgs/two-A4-splitted_full.jpg\")\n",
    "print(\"Resolution: {}x{}\".format(queryImg.shape[0], queryImg.shape[1]))\n",
    "\n",
    "%timeit corners, ids, _ = aruco.detectMarkers(queryImg, ARUCO_DICT, parameters=ARUCO_PARAMETERS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideration about absolute timing cannot be provided, because it depends on the platform used.\\\n",
    "In Desktop PC the timeit returns an exection time of ?, contrariwise, on a SBC it took 227ms ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Black/white image\n",
    "We now try to do better. We consider a black/white image that is more light wrt memory occupation. We should also consider that camera image would be colored, so it is also relevant time spent for \"cvtColor\" function to convert the image. Image is full resolution also for this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182 ms ± 3.61 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "grayQueryImg = cv2.cvtColor(queryImg, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "%timeit corners, ids, _ = aruco.detectMarkers(grayQueryImg, ARUCO_DICT, parameters=ARUCO_PARAMETERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only detectMarkers function seems to perform better with b/w image. The converted image can also be used later on the program to perform edge recognition, so must take notes about the speed up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtered image\n",
    "We now try if filtering the image can speed up the search, due to the fact that less details are present in image. Also for this test, take full resolution image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First try with a **bilateral filter**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156 ms ± 5.92 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "queryFiltered = cv2.bilateralFilter(queryImg, 9, 75, 75, cv2.BORDER_DEFAULT)\n",
    "\n",
    "%timeit corners, ids, _ = aruco.detectMarkers(queryFiltered, ARUCO_DICT, parameters=ARUCO_PARAMETERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a speed up of about 31% wrt the detection without filtering, but we need to check if the filtering function is \"time-friendly\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.43 s ± 155 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit queryFiltered_second = cv2.bilateralFilter(queryImg, 9, 75, 75, cv2.BORDER_DEFAULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So filtering is a very time-harvesting operation, one order of magnitude more than the plain search. If not needed for successive elaboration of the image, must consider carefully apply a filter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try also with other filtering e.g. **Non-local Means Denoising**, already implemented in cv2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.8 s ± 270 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit queryFiltered = cv2.fastNlMeansDenoisingColored(queryImg, h=2, hColor=3, templateWindowSize=5, searchWindowSize=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that despite of the good results, it's a very slow algorithm. Settings are also being lowered respect to the suggested, to get better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaled image\n",
    "We now try with a scaled version of the iamge. This could be not very good for edge detection, some light edge can be masked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resized Dimensions : (1176, 2419, 3)\n"
     ]
    }
   ],
   "source": [
    "# Make a scaled version of the original image\n",
    "scale_perc = 60 # percent of original size\n",
    "width = int(queryImg.shape[1] * scale_perc / 100)\n",
    "height = int(queryImg.shape[0] * scale_perc / 100)\n",
    "dim = (width, height)\n",
    "\n",
    "imgResized = cv2.resize(queryImg, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "print(\"Resized Dimensions :\", imgResized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 ms ± 2.48 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit corners, ids, _ = aruco.detectMarkers(imgResized, ARUCO_DICT, parameters=ARUCO_PARAMETERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a scaled version of the image we get a speedup of about 67%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final considerations\n",
    "Filtering the image not seems to be useful wrt the aruco recognition, regarding the computational time.\\\n",
    "Depending on the final camera specifications, the image can be upscaled or downscaled to get optimal performace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
